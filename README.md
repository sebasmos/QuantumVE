[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
[![Python Version](https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12-blue.svg)](https://github.com/sebasmos/QuantumVE/) 
[![arXiv](https://img.shields.io/badge/arXiv-2508.00024-b31b1b.svg)](https://arxiv.org/abs/2508.00024)

# QuantumVE: Quantum-Transformer Advantage Boost Over Classical ML

**Breaking Discovery:** Vision Transformer embeddings unlock quantum machine learning advantage! First systematic proof that embedding choice determines quantum kernel success, revealing fundamental synergy between transformer attention and quantum feature spaces.

- ğŸ“‚ **GitHub Repository**: [QuantumVE](https://github.com/sebasmos/QuantumVE)
- ğŸ“„ **Research Paper**: [Embedding-Aware Quantum-Classical SVMs for Scalable Quantum Machine Learning](https://arxiv.org/abs/2508.00024)
- ğŸ’» **Dataset on HuggingFace**: [QuantumEmbeddings](https://huggingface.co/datasets/sebasmos/QuantumEmbeddings)

## ğŸ¯ Breakthrough Results

- **8.02%** accuracy improvement on Fashion-MNIST vs classical SVMs
- **4.42%** boost on MNIST dataset  
- **First evidence** that ViT embeddings enable quantum advantage while CNN features show degradation
- **16-qubit** tensor network simulation via cuTensorNet proving scalability
- **Class-balanced k-means distillation** for efficient quantum processing

## Project Architecture

```
QuantumVE/
â”œâ”€â”€ data_processing/     # Class-balanced k-means distillation procedures
â”œâ”€â”€ embeddings/          # Vision Transformer & CNN embedding extraction
â”œâ”€â”€ qve/                 # Core quantum-classical modules and utilities
â””â”€â”€ scripts/             # Experimental pipelines with cross-validation
    â”œâ”€â”€ classical_baseline.py           # Traditional SVM benchmarks
    â”œâ”€â”€ cross_validation_baseline.py    # Cross-validation framework
    â””â”€â”€ qsvm_cuda_embeddings.py         # Our embedding-aware quantum method
```

## ğŸš€ Quick Start

### 1. Environment Setup
```bash
# Create conda environment
conda create -n QuantumVE python=3.11 -y
conda activate QuantumVE

# Clone and install
git clone https://github.com/sebasmos/QuantumVE.git
cd QuantumVE
pip install -e .

# For Ryzen devices - Install MPI
conda install -c conda-forge mpi4py openmpi
```

### 2. Download Pre-computed Embeddings

**MNIST Embeddings:**
```bash
mkdir -p data && \
wget https://huggingface.co/datasets/sebasmos/QuantumEmbeddings/resolve/main/mnist_embeddings.zip && \
unzip mnist_embeddings.zip -d data && \
rm mnist_embeddings.zip
```

**Fashion-MNIST Embeddings:**
```bash
mkdir -p data && \
wget https://huggingface.co/datasets/sebasmos/QuantumEmbeddings/resolve/main/fashionmnist_embeddings.zip && \
unzip fashionmnist_embeddings.zip -d data && \
rm fashionmnist_embeddings.zip
```

### 3. Run Experiments

**Single Node:**
```bash
# Classical baseline with cross-validation
python scripts/classical_baseline.py

# Cross-validation framework  
python scripts/cross_validation_baseline.py

# Our embedding-aware quantum method
python scripts/qsvm_cuda_embeddings.py
```

**Multi-Node with MPI:**
```bash
# Run with 2 processes
mpirun -np 2 python scripts/qsvm_cuda_embeddings.py
mpirun -np 2 python scripts/cross_validation_baseline.py
```

## ğŸ”¬ What Makes This Work?

Our key insight: **embedding choice is critical for quantum advantage**. While CNN features degrade in quantum systems, Vision Transformer embeddings create a unique synergy with quantum feature spaces, enabling measurable performance gains through:

1. **Class-balanced distillation** reduces quantum overhead while preserving critical patterns
2. **ViT attention mechanisms** align naturally with quantum superposition states
3. **Tensor network simulation** scales to practical problem sizes (16+ qubits)

## ğŸ¤ Contributing

We welcome contributions! Help us advance quantum machine learning:

1. Fork the [QuantumVE repository](https://github.com/sebasmos/QuantumVE)
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Submit a pull request with detailed description

**Areas for contribution:**
- New embedding architectures (BERT, CLIP, etc.)
- Additional quantum backends
- Performance optimizations
- Documentation improvements

## ğŸ™ Acknowledgements

This work was supported by the **Google Cloud Research Credits program** under award number **GCP19980904**.

## ğŸ“„ License

[CC BY-NC-SA 4.0](https://github.com/sebasmos/QuantumVE/blob/main/LICENSE).

## ğŸ“š Citation

### Paper
```bibtex
@article{Cajas2024_QuantumVE,
  title={Embedding-Aware Quantum-Classical SVMs for Scalable Quantum Machine Learning},
  author={Cajas OrdÃ³Ã±ez, SebastiÃ¡n AndrÃ©s and Torres Torres, Luis and Bifulco, Mario and Duran, Carlos and Bosch, Cristian and SimÃ³n Carbajo, Ricardo},
  journal={arXiv preprint arXiv:2508.00024},
  year={2024},
  url={https://arxiv.org/abs/2508.00024}
}
```

---

<div align="center">

**ğŸŒŸ Star us on GitHub if this helps your research! ğŸŒŸ**

</div>
